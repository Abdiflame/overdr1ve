{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4dc9f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os, sys, inspect\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "sys.path.append(os.getcwd())\n",
    "from overdr1ve_env import Overdr1veEnv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2c2dc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_type_bonus(cell: str):\n",
    "    if not isinstance(cell, str):\n",
    "        return 0, 0\n",
    "    s = cell.strip()\n",
    "    if not s:\n",
    "        return 0, 0\n",
    "    parts = s.split()\n",
    "    try:\n",
    "        val = int(parts[0])\n",
    "    except Exception:\n",
    "        return 0, 0\n",
    "    rest = \" \".join(parts[1:]).lower()\n",
    "    if \"core\" in rest:\n",
    "        return val, 0\n",
    "    if \"max\" in rest:\n",
    "        return 0, val\n",
    "    return 0, 0\n",
    "\n",
    "def split_types(cell: str):\n",
    "    if not isinstance(cell, str):\n",
    "        return set()\n",
    "    s = cell.strip()\n",
    "    if s == \"-\" or s == \"\":\n",
    "        return set()\n",
    "    return {p.strip() for p in s.split(\"/\") if p.strip()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83d8c870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Parameters\n",
    "# tracks_csv = \"data_csv/tracks.csv\"\n",
    "# cars_csv = \"data_csv/cars.csv\"\n",
    "# upgrades_csv = \"data_csv/upgrades.csv\"\n",
    "\n",
    "# ppo_model_path = \"./checkpoints/ppo_overdr1ve\"  # without .zip\n",
    "# vecnorm_path = \"./checkpoints/vecnorm_stats.pkl\"\n",
    "\n",
    "# EPISODES = 200\n",
    "# AGENT_ID = 0\n",
    "# SHUFFLE_TRACKS = True\n",
    "\n",
    "# # Load DataFrames used by the offline simulator\n",
    "# tracks_df = pd.read_csv(tracks_csv)\n",
    "# cars_df = pd.read_csv(cars_csv)\n",
    "# upgrades_df = pd.read_csv(upgrades_csv)\n",
    "\n",
    "# tracks_df = tracks_df.copy()\n",
    "# tracks_df[\"bonus_core\"], tracks_df[\"bonus_max\"] = zip(*tracks_df[\"Type Bonus\"].map(parse_type_bonus))\n",
    "\n",
    "# upgrades_df = upgrades_df.copy()\n",
    "# upgrades_df[\"cond_set\"] = upgrades_df[\"Track Type Condition\"].map(split_types)\n",
    "\n",
    "# POINTS = [25, 18, 15, 12, 10, 8, 6, 4, 2, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45bc5508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Offline simulator for Random/Greedy\n",
    "rng = np.random.default_rng(12345)\n",
    "\n",
    "def episode_tracks(df: pd.DataFrame, shuffle: bool):\n",
    "    if shuffle:\n",
    "        return df.sample(frac=1.0, random_state=int(rng.integers(0, 1_000_000))).reset_index(drop=True)\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "def eval_action_points_on_track(track_row, agent_car_row, action_row, opponents_df):\n",
    "    # track bonuses\n",
    "    ttype = track_row[\"Track Type\"]\n",
    "    req_laps = int(track_row[\"Total Laps\"])\n",
    "    b_core = int(track_row[\"bonus_core\"]) if not np.isnan(track_row[\"bonus_core\"]) else 0\n",
    "    b_max  = int(track_row[\"bonus_max\"])  if not np.isnan(track_row[\"bonus_max\"])  else 0\n",
    "\n",
    "    # agent base\n",
    "    a_core = float(agent_car_row[\"Core Power\"]) + b_core\n",
    "    a_max  = int(agent_car_row[\"Max Laps\"]) + b_max\n",
    "    cond = action_row[\"cond_set\"]\n",
    "    if (len(cond) == 0) or (ttype in cond):\n",
    "        a_core += float(action_row[\"Core Power\"])  # upgrade core\n",
    "        a_max  += int(action_row[\"Max Laps\"])     # upgrade max\n",
    "    a_dnf = a_max < req_laps\n",
    "\n",
    "    # opponents\n",
    "    o_core = opponents_df[\"Core Power\"].to_numpy(float) + b_core\n",
    "    o_max  = opponents_df[\"Max Laps\"].to_numpy(int) + b_max\n",
    "    o_dnf  = o_max < req_laps\n",
    "\n",
    "    grid_core = np.concatenate([o_core, np.array([a_core])])\n",
    "    grid_dnf  = np.concatenate([o_dnf,  np.array([a_dnf])])\n",
    "    idxs = np.arange(len(grid_core))\n",
    "    noise = np.linspace(0, 1e-6, len(grid_core))\n",
    "    order = sorted(idxs, key=lambda i: (grid_dnf[i], -(grid_core[i] + noise[i])))\n",
    "    agent_idx = len(grid_core) - 1\n",
    "    pos = order.index(agent_idx) + 1\n",
    "    pts = POINTS[pos - 1] if not a_dnf else 0\n",
    "    return pts, not a_dnf, (pos == 1 and not a_dnf)\n",
    "\n",
    "def run_offline_mode(mode, episodes=100, agent_id=0, shuffle=True):\n",
    "    rows = []\n",
    "    agent_car = cars_df.iloc[agent_id]\n",
    "    opponents = cars_df.drop(agent_id).reset_index(drop=True)\n",
    "    # include a synthetic \"No Upgrade\" that does nothing\n",
    "    actions = pd.concat([\n",
    "        pd.DataFrame([{ \"Upgrade\": \"No Upgrade\", \"Core Power\": 0.0, \"Max Laps\": 0, \"Track Type Condition\": \"-\", \"cond_set\": set() }]),\n",
    "        upgrades_df\n",
    "    ], ignore_index=True)\n",
    "\n",
    "    for ep in range(episodes):\n",
    "        tr_order = episode_tracks(tracks_df, shuffle)\n",
    "        total_points, finishes, wins = 0.0, 0, 0\n",
    "        for _, tr in tr_order.iterrows():\n",
    "            if mode == \"Random\":\n",
    "                a_idx = int(rng.integers(0, len(actions)))\n",
    "            elif mode == \"Greedy\":\n",
    "                # choose action maximizing points on this track\n",
    "                best_pts, best_idx = -1, 0\n",
    "                for i, a in actions.iterrows():\n",
    "                    pts, finished, won = eval_action_points_on_track(tr, agent_car, a, opponents)\n",
    "                    if pts > best_pts:\n",
    "                        best_pts, best_idx = pts, i\n",
    "                a_idx = best_idx\n",
    "            else:\n",
    "                raise ValueError(\"mode must be Random or Greedy in offline sim\")\n",
    "\n",
    "            pts, finished, won = eval_action_points_on_track(tr, agent_car, actions.iloc[a_idx], opponents)\n",
    "            total_points += pts\n",
    "            finishes += int(finished)\n",
    "            wins += int(won)\n",
    "\n",
    "        tracks_played = len(tr_order)\n",
    "        rows.append({\n",
    "            \"Mode\": mode,\n",
    "            \"Episode\": ep + 1,\n",
    "            \"Total Points\": total_points,\n",
    "            \"Finishes\": finishes,\n",
    "            \"Wins\": wins,\n",
    "            \"Tracks\": tracks_played,\n",
    "            \"Finish Rate\": finishes / max(1, tracks_played),\n",
    "            \"Avg Points / Track\": total_points / max(1, tracks_played),\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02cd593c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "import inspect, os, pandas as pd\n",
    "\n",
    "# ---- helpers to normalize vecenv API differences (gym vs gymnasium) ----\n",
    "def vec_reset(venv):\n",
    "    \"\"\"Return (obs, info) for both old/new APIs.\"\"\"\n",
    "    out = venv.reset()\n",
    "    if isinstance(out, tuple) and len(out) == 2:\n",
    "        return out  # (obs, info) new API\n",
    "    return out, {}  # old API: just obs\n",
    "\n",
    "def vec_step(venv, action):\n",
    "    \"\"\"\n",
    "    Return (obs, reward, terminated, truncated, info, done_bool_array)\n",
    "    for both old (4-tuple) and new (5-tuple) APIs.\n",
    "    \"\"\"\n",
    "    out = venv.step(action)\n",
    "    if isinstance(out, tuple) and len(out) == 5:\n",
    "        obs, reward, terminated, truncated, info = out\n",
    "        done = np.logical_or(terminated, truncated)\n",
    "        return obs, reward, terminated, truncated, info, done\n",
    "    # old API: (obs, reward, done, info)\n",
    "    obs, reward, done, info = out\n",
    "    done = np.asarray(done, dtype=bool)\n",
    "    terminated = done\n",
    "    truncated = np.zeros_like(done, dtype=bool)\n",
    "    return obs, reward, terminated, truncated, info, done\n",
    "\n",
    "# ---- env factory that tolerates your constructor signature ----\n",
    "def make_env_any_signature(tracks_csv, cars_csv, upgrades_csv, agent_car_id=0, shuffle_tracks=True):\n",
    "    from overdr1ve_env import Overdr1veEnv  # import here to reflect live edits\n",
    "    sig = inspect.signature(Overdr1veEnv.__init__)\n",
    "    params = set(sig.parameters.keys())\n",
    "\n",
    "    def _thunk():\n",
    "        # Case 1: expects DataFrames named track_df/car_df/upgrade_df\n",
    "        if {\"track_df\", \"car_df\"}.issubset(params):\n",
    "            env = Overdr1veEnv(\n",
    "                track_df=pd.read_csv(tracks_csv),\n",
    "                car_df=pd.read_csv(cars_csv),\n",
    "                upgrade_df=pd.read_csv(upgrades_csv) if (upgrades_csv and os.path.exists(upgrades_csv)) else None,\n",
    "                episode_len=len(pd.read_csv(tracks_csv)) if \"episode_len\" in params else None,\n",
    "                opponent_mode=\"static\" if \"opponent_mode\" in params else None,\n",
    "                penalty_dnf=0.0 if \"penalty_dnf\" in params else None,\n",
    "            )\n",
    "        # Case 2: refactored DF-based version\n",
    "        elif {\"tracks_df\", \"cars_df\"}.issubset(params):\n",
    "            env = Overdr1veEnv(\n",
    "                tracks_df=pd.read_csv(tracks_csv),\n",
    "                cars_df=pd.read_csv(cars_csv),\n",
    "                upgrades_df=pd.read_csv(upgrades_csv) if (upgrades_csv and os.path.exists(upgrades_csv)) else None,\n",
    "                agent_car_id=agent_car_id if \"agent_car_id\" in params else 0,\n",
    "                shuffle_tracks_each_reset=shuffle_tracks if \"shuffle_tracks_each_reset\" in params else False,\n",
    "            )\n",
    "        # Case 3: CSV-path-based version\n",
    "        elif {\"tracks_csv\", \"cars_csv\"}.issubset(params):\n",
    "            kwargs = dict(tracks_csv=tracks_csv, cars_csv=cars_csv)\n",
    "            if \"upgrades_csv\" in params:\n",
    "                kwargs[\"upgrades_csv\"] = upgrades_csv\n",
    "            if \"agent_car_id\" in params:\n",
    "                kwargs[\"agent_car_id\"] = agent_car_id\n",
    "            if \"shuffle_tracks_each_reset\" in params:\n",
    "                kwargs[\"shuffle_tracks_each_reset\"] = shuffle_tracks\n",
    "            env = Overdr1veEnv(**kwargs)\n",
    "        else:\n",
    "            raise TypeError(f\"Unrecognized Overdr1veEnv constructor params: {sorted(params)}\")\n",
    "        return Monitor(env)\n",
    "    return _thunk\n",
    "\n",
    "# ---- patched PPO eval using the normalized helpers ----\n",
    "def run_ppo_env_eval(tracks_csv, cars_csv, upgrades_csv,\n",
    "                     ppo_model_path=\"./checkpoints/ppo_overdr1ve\",\n",
    "                     vecnorm_path=\"./checkpoints/vecnorm_stats.pkl\",\n",
    "                     agent_id=0, shuffle_tracks=True, episodes=100):\n",
    "    from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n",
    "\n",
    "    venv = DummyVecEnv([make_env_any_signature(tracks_csv, cars_csv, upgrades_csv, agent_id, shuffle_tracks)])\n",
    "\n",
    "    # Load VecNormalize if available\n",
    "    if os.path.exists(vecnorm_path):\n",
    "        venv = VecNormalize.load(vecnorm_path, venv)\n",
    "        venv.training = False\n",
    "        venv.norm_reward = False\n",
    "\n",
    "    if not os.path.exists(ppo_model_path + \".zip\"):\n",
    "        raise FileNotFoundError(f\"Missing PPO model file: {ppo_model_path}.zip\")\n",
    "\n",
    "    model = PPO.load(ppo_model_path, env=venv, device=\"cpu\")\n",
    "\n",
    "    rows = []\n",
    "    for ep in range(episodes):\n",
    "        obs, info = vec_reset(venv)\n",
    "        done_all = False\n",
    "        total_points = 0.0\n",
    "        finishes = 0\n",
    "        wins = 0\n",
    "        tracks_played = 0\n",
    "\n",
    "        while not done_all:\n",
    "            action, _ = model.predict(obs, deterministic=True)\n",
    "            obs, reward, terminated, truncated, info_step, done = vec_step(venv, action)\n",
    "\n",
    "            # vec env returns arrays per env\n",
    "            d = info_step[0] if isinstance(info_step, (list, tuple)) else info_step\n",
    "            total_points += float(np.asarray(reward)[0])\n",
    "            finished = not bool(d.get(\"agent_dnf\", False))\n",
    "            if finished:\n",
    "                finishes += 1\n",
    "            if finished and int(d.get(\"position\", 99)) == 1:\n",
    "                wins += 1\n",
    "            tracks_played += 1\n",
    "            done_all = bool(np.asarray(done)[0])\n",
    "\n",
    "        rows.append({\n",
    "            \"Mode\": \"PPO\",\n",
    "            \"Episode\": ep + 1,\n",
    "            \"Total Points\": total_points,\n",
    "            \"Finishes\": finishes,\n",
    "            \"Wins\": wins,\n",
    "            \"Tracks\": tracks_played,\n",
    "            \"Finish Rate\": finishes / max(1, tracks_played),\n",
    "            \"Avg Points / Track\": total_points / max(1, tracks_played),\n",
    "        })\n",
    "    import pandas as pd\n",
    "    return pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12b29776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Total_Points_Mean  Total_Points_Std  Avg_Points_per_Track  Finish_Rate    Wins\n",
      "Mode                                                                                  \n",
      "Greedy            300.000             0.000                25.000        1.000  12.000\n",
      "PPO               237.590            12.429                19.799        1.000   5.665\n",
      "Random            183.595            24.852                15.300        0.953   3.045\n"
     ]
    }
   ],
   "source": [
    "# Params (adjust if needed)\n",
    "tracks_csv = \"data_csv/tracks.csv\"\n",
    "cars_csv = \"data_csv/cars.csv\"\n",
    "upgrades_csv = \"data_csv/upgrades.csv\"\n",
    "ppo_model_path = \"./checkpoints/ppo_overdr1ve\"\n",
    "vecnorm_path = \"./checkpoints/vecnorm_stats.pkl\"\n",
    "\n",
    "EPISODES = 200\n",
    "AGENT_ID = 0\n",
    "SHUFFLE_TRACKS = True\n",
    "\n",
    "# # Load DataFrames used by the offline simulator\n",
    "tracks_df = pd.read_csv(tracks_csv)\n",
    "cars_df = pd.read_csv(cars_csv)\n",
    "upgrades_df = pd.read_csv(upgrades_csv)\n",
    "\n",
    "tracks_df = tracks_df.copy()\n",
    "tracks_df[\"bonus_core\"], tracks_df[\"bonus_max\"] = zip(*tracks_df[\"Type Bonus\"].map(parse_type_bonus))\n",
    "\n",
    "upgrades_df = upgrades_df.copy()\n",
    "upgrades_df[\"cond_set\"] = upgrades_df[\"Track Type Condition\"].map(split_types)\n",
    "\n",
    "POINTS = [25, 18, 15, 12, 10, 8, 6, 4, 2, 1]\n",
    "\n",
    "# Evaluate PPO with env (robust to API/version differences)\n",
    "df_ppo = run_ppo_env_eval(\n",
    "    tracks_csv, cars_csv, upgrades_csv,\n",
    "    ppo_model_path=ppo_model_path,\n",
    "    vecnorm_path=vecnorm_path,\n",
    "    agent_id=AGENT_ID,\n",
    "    shuffle_tracks=SHUFFLE_TRACKS,\n",
    "    episodes=EPISODES\n",
    ")\n",
    "\n",
    "# You already had:\n",
    "df_random = run_offline_mode(\"Random\", episodes=EPISODES, agent_id=AGENT_ID, shuffle=SHUFFLE_TRACKS)\n",
    "df_greedy = run_offline_mode(\"Greedy\", episodes=EPISODES, agent_id=AGENT_ID, shuffle=SHUFFLE_TRACKS)\n",
    "\n",
    "# Combine and summarize\n",
    "import pandas as pd\n",
    "summary = pd.concat([df_random, df_greedy, df_ppo], ignore_index=True)\n",
    "\n",
    "mode_agg = summary.groupby(\"Mode\").agg(\n",
    "    Total_Points_Mean=(\"Total Points\", \"mean\"),\n",
    "    Total_Points_Std=(\"Total Points\", \"std\"),\n",
    "    Avg_Points_per_Track=(\"Avg Points / Track\", \"mean\"),\n",
    "    Finish_Rate=(\"Finish Rate\", \"mean\"),\n",
    "    Wins=(\"Wins\", \"mean\"),\n",
    ").round(3)\n",
    "\n",
    "print(mode_agg.to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14572250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total_Points_Mean</th>\n",
       "      <th>Total_Points_Std</th>\n",
       "      <th>Avg_Points_per_Track</th>\n",
       "      <th>Finish_Rate</th>\n",
       "      <th>Wins</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mode</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Greedy</th>\n",
       "      <td>300.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>25.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>12.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PPO</th>\n",
       "      <td>237.590</td>\n",
       "      <td>12.429</td>\n",
       "      <td>19.799</td>\n",
       "      <td>1.000</td>\n",
       "      <td>5.665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random</th>\n",
       "      <td>183.595</td>\n",
       "      <td>24.852</td>\n",
       "      <td>15.300</td>\n",
       "      <td>0.953</td>\n",
       "      <td>3.045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Total_Points_Mean  Total_Points_Std  Avg_Points_per_Track  \\\n",
       "Mode                                                                \n",
       "Greedy            300.000             0.000                25.000   \n",
       "PPO               237.590            12.429                19.799   \n",
       "Random            183.595            24.852                15.300   \n",
       "\n",
       "        Finish_Rate    Wins  \n",
       "Mode                         \n",
       "Greedy        1.000  12.000  \n",
       "PPO           1.000   5.665  \n",
       "Random        0.953   3.045  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mode_agg = summary.groupby(\"Mode\").agg(\n",
    "    Total_Points_Mean=(\"Total Points\", \"mean\"),\n",
    "    Total_Points_Std=(\"Total Points\", \"std\"),\n",
    "    Avg_Points_per_Track=(\"Avg Points / Track\", \"mean\"),\n",
    "    Finish_Rate=(\"Finish Rate\", \"mean\"),\n",
    "    Wins=(\"Wins\", \"mean\"),\n",
    ").round(3)\n",
    "mode_agg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1061fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg = summary.groupby(\"Mode\").agg(\n",
    "    mean_points=(\"Total Points\", \"mean\"),\n",
    "    std_points=(\"Total Points\", \"std\"),\n",
    "    finish=(\"Finish Rate\", \"mean\"),\n",
    "    wins=(\"Wins\", \"mean\"),\n",
    "    apt=(\"Avg Points / Track\", \"mean\"),\n",
    ").reset_index()\n",
    "\n",
    "x = np.arange(len(agg))\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.bar(x, agg[\"mean_points\"], yerr=agg[\"std_points\"], capsize=4)\n",
    "plt.xticks(x, agg[\"Mode\"])\n",
    "plt.ylabel(\"Total Points (mean ± std)\")\n",
    "plt.title(\"Total Points by Mode\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.bar(x, agg[\"finish\"]) ; plt.ylim(0,1)\n",
    "plt.xticks(x, agg[\"Mode\"]) ; plt.ylabel(\"Finish Rate\")\n",
    "plt.title(\"Finish Rate by Mode\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.bar(x, agg[\"wins\"]) ; plt.xticks(x, agg[\"Mode\"]) ; plt.ylabel(\"Wins\")\n",
    "plt.title(\"Wins by Mode\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.bar(x, agg[\"apt\"]) ; plt.xticks(x, agg[\"Mode\"]) ; plt.ylabel(\"Avg Points / Track\")\n",
    "plt.title(\"Avg Points / Track by Mode\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984921b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detectron2-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
